{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNBN12irsP9aDkn10xeugKu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**WEEK-2 NOTES**"],"metadata":{"id":"P4CJclGBOj2v"}},{"cell_type":"markdown","source":["\n","##**PART 1 Feature Extraction**"],"metadata":{"id":"GWOvHNaX_K2O"}},{"cell_type":"code","source":["from sklearn.feature_extraction import DictVectorizer, FeatureHasher"],"metadata":{"id":"pQ-lD5acZ2IP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["  * **DictVectorizer**\n","\n","    Converts lists of mappings of feature name and feature value into a matrix\n","\n","  * **FeatureHasher**\n","\n","    uses feature hashing technique\n","\n","    instead of building a hash table of the features (as the vectorizers do it applies a HASH FUNCTION to the features to deatermine their column index in sample matrices directly.\n","\n","    this results in increased speed and reduced memory usage, at the expense of inspectability.\n","\n","    the hasher does not remember what the input features looked like and has no inverse_transform method.\n","\n","    output of this transformer is scipy.sparse matrix.\n","\n","  * **Feature Extraction of Non-Numerical Values**\n","\n","    from Images\n","\n","    `sklearn.feature_extraction.image.*`\n","\n","    from Text\n","\n","    `sklearn.feature_extraction.text.*`"],"metadata":{"id":"GR48eduxaQJE"}},{"cell_type":"markdown","source":["\n","##**PART 2 Data Cleaning**"],"metadata":{"id":"cvxUV4rz_Ufx"}},{"cell_type":"markdown","source":["### **1. Handling Missing Values**"],"metadata":{"id":"wXE0kYICXU9f"}},{"cell_type":"markdown","source":["  * Handling Missing Values\n","\n","    `sklearn.impute` API provides functionality to fill missing values in a dataset\n","\n","    `MissingIndicator` class provides indicators for missing values\n","\n","   1.  SimpleImputer\n","      * Fills missing values with one of the following strategies :\n","    `'mean'`, `'median'` , `'most_frequent`' and `'constant'`\n","\n","    2.  KNNImputer\n","      * Uses k-nearest neighbours approach to fill missing values in a dataset.\n","    The missing value of an attribute in a specicfic example is filled with the mean vlue of the same attribute of `n_neighbors` closest neighbors.\n","      * The nearest neighbors are decided based on Euclidean distance."],"metadata":{"id":"sLz4SB8bdyul"}},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer, KNNImputer\n","\n","X = [[]] #original feature matrix"],"metadata":{"id":"C8mhfkYWOmRX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Simple Imputer\n","\n","si = SimpleImputer(strategy = 'mean')\n","si.fit_transform(X) # tranformed feature matrix"],"metadata":{"id":"_6HYA14siRGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#KNN Imputer\n","\n","knni = KNNImputer(n_neighbors = 2, weights = 'uniform')\n","knni.fit_transform(X) # tranformed feature matrix"],"metadata":{"id":"TQYws3LNiHlH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**2. Numerical Transformers**"],"metadata":{"id":"owaxTIOUi9HZ"}},{"cell_type":"markdown","source":["#### i . Standard Scalar\n","\n"],"metadata":{"id":"sRLehoQOl-SM"}},{"cell_type":"markdown","source":["  * Transforms the original features vector x into a new feature vector x' using the following formula :\n","\n","  ùêó' = $\\frac{ùöá - Œº}{œÉ}$\n"],"metadata":{"id":"nTzsJJK5vSMW"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"1eAcyzh_kTD1"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"k79HvslRrS_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#activity question\n","\n","import numpy as np\n","\n","a = np.array([0,3,6])\n","x = a.reshape(-1,1)"],"metadata":{"id":"_wiJVVU-rWiX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Standard Scaler\n","\n","ss = StandardScaler()\n","ss.fit_transform(x) #fit transform learns the parameters mu and sigma from the original feature matrix"],"metadata":{"id":"zj5NxKhrrZhN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####ii. MinMaxScaler\n"],"metadata":{"id":"KmBPVvbXmIIC"}},{"cell_type":"markdown","source":["  * It transforms the original feature vector x into new feature vector x' so that all values fall within the range [0,1] using the following formula:\n","\n","  ùêó' = $\\frac{ùêó - ùêó.min}{ùêó.max - ùêó.min}$\n","\n","  where x.max and x.min are largest and smallest values of that feature respectively of the original feature vector x\n","\n","  * the largest number is transformed to 1 and the smallest number is transformed to 0"],"metadata":{"id":"k7fyckGRvcgl"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler"],"metadata":{"id":"asQ9aGhnsgjE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#MinMaxScaler\n","\n","mms = MinMaxScaler()\n","mms.fit_transform(x)"],"metadata":{"id":"gr-fxKQttUtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### iii. MaxAbsScaler\n","\n","\n"],"metadata":{"id":"uvOaUBPSt6Ik"}},{"cell_type":"markdown","source":["  * It transforms the original features vector x into new feature vector x' so that all values fall within range [-1,1]\n","\n"," ùêó' = $\\frac{ùêó}{MaxAbsoluteValue}$\n","\n","  where `MaxAbsoluteValue = max( x.max, |x.min| )`"],"metadata":{"id":"4bYgEBs8vh55"}},{"cell_type":"code","source":["from sklearn.preprocessing import MaxAbsScaler"],"metadata":{"id":"GyvufiJ3uyE1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#MaxAbsScaler\n","\n","mas = MaxAbsScaler()\n","mas.fit_transform(x)"],"metadata":{"id":"AYMCUgeeuoJB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####iv. FunctionTransformer"],"metadata":{"id":"kkp6eoM0u92D"}},{"cell_type":"markdown","source":["  * Constructs tranformed features by applying a USER DEFINED function"],"metadata":{"id":"KlVmwbS0vlhA"}},{"cell_type":"code","source":["from sklearn.preprocessing import FunctionTransformer"],"metadata":{"id":"e3BtxjOnvQQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#FunctionTransformer\n","import numpy\n","\n","ft = FunctionTransformer(numpy.log2)\n","ft.fit_transform(x)"],"metadata":{"id":"CHgTzKQ_v2Hi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####v. Polynomial Transformation"],"metadata":{"id":"xUD7vZKMwNMt"}},{"cell_type":"markdown","source":["  * Generates a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree"],"metadata":{"id":"uSNft2Howh1P"}},{"cell_type":"code","source":["from sklearn.preprocessing import PolynomialFeatures"],"metadata":{"id":"SyA9U-efwP3W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Polynomial Transformation\n","\n","pf = PolynomialFeatures(degree = 2)\n","pf.fit_transform(x)"],"metadata":{"id":"iwGt6CFXw4Jc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### vi. KBinsDiscretizer"],"metadata":{"id":"l_V0qJ5RxFKI"}},{"cell_type":"markdown","source":["  * Divides a continuous variable into bins\n","  * One hot encoding or Ordinal encoding is further applied to the bin labels"],"metadata":{"id":"gRpYGHh7xh6T"}},{"cell_type":"code","source":["from sklearn.preprocessing import KBinsDiscretizer"],"metadata":{"id":"vTL-gwTqxQlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#KBinsDiscretizer\n","\n","kbd = KBinsDiscretizer(n_bins = 5, strategy = 'uniform', encode = 'ordinal')\n","kbd.fit_transform(x)"],"metadata":{"id":"JlcjGC2OyBMz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**3. Categorical transformers**\n","for categorical feature encoding and for label encoding"],"metadata":{"id":"67FK0xz6y92h"}},{"cell_type":"markdown","source":["#### i. OneHotEncoder"],"metadata":{"id":"g3kUxTL_zxBg"}},{"cell_type":"markdown","source":["  * Encodes categorical feature or label as a one-hot numeric array\n","  * Creates one binary column for each of K unique values\n","  * Exactly one column has 1 in it and rest have 0"],"metadata":{"id":"4FcMalcNz1ya"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder"],"metadata":{"id":"nRCj4AWZ0IEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#OneHotEncoder\n","\n","ohe = OneHotEncoder()\n","ohe.fit_transform(x)"],"metadata":{"id":"1HvwGLGo0MlP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example :\n"],"metadata":{"id":"_aB2UOilUVCg"}},{"cell_type":"code","source":["import numpy as np\n","\n","l = np.array([1,2,3,1])\n","a = l.reshape(-1,1)\n","\n","ohe = OneHotEncoder()\n","new = ohe.fit_transform(a)\n","\n","print(new)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmggNvqKUXd_","executionInfo":{"status":"ok","timestamp":1687693261073,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gagneet Kaur","userId":"01282326010698350277"}},"outputId":"cf2eab70-0dcc-4c5d-e469-2c7f635c1380"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  (0, 0)\t1.0\n","  (1, 1)\t1.0\n","  (2, 2)\t1.0\n","  (3, 0)\t1.0\n"]}]},{"cell_type":"markdown","source":["#### ii. LabelEncoder"],"metadata":{"id":"Bv9c0GGZ0osA"}},{"cell_type":"markdown","source":["  * Encodes target labels with value between 0 and K-1, where K is number of distinct values"],"metadata":{"id":"U-dPeZDb0rXW"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder"],"metadata":{"id":"2zGu-0ho03Kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LabelEncoder\n","\n","le = LabelEncoder()\n","le.fit_transform(x)"],"metadata":{"id":"WaKyMu5g07gE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Example :"],"metadata":{"id":"kfpLYuimV3lm"}},{"cell_type":"code","source":["l = np.array([1,2,6,1,8,6])\n","\n","le = LabelEncoder()\n","transformed_vector = le.fit_transform(l)\n","print(transformed_vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tTj94z7V6Mz","executionInfo":{"status":"ok","timestamp":1687693195474,"user_tz":-330,"elapsed":416,"user":{"displayName":"Gagneet Kaur","userId":"01282326010698350277"}},"outputId":"c5fb374e-3951-4c6b-d3a4-86e828b2200e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 0 3 2]\n"]}]},{"cell_type":"markdown","source":["#### iii. OrdinalEncoder"],"metadata":{"id":"itNAhwJ91XDe"}},{"cell_type":"markdown","source":["* Encodes categorical features with value between 0 and K-1 (where K is the no. of distinct values)\n","* **OrdinalEncoder** can operate multi-dimensional data, while **LabelEncoder** can only transform 1-D data"],"metadata":{"id":"CzU8vG4GXDnw"}},{"cell_type":"code","source":["from sklearn.preprocessing import OrdinalEncoder"],"metadata":{"id":"6I86CvmZXOln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c = np.array([[1, 'male'], [2, 'female'], [6, 'female'], [1, 'male'], [8, 'male'], [6, 'female']])\n","\n","oe = OrdinalEncoder()\n","transformed_c = oe.fit_transform(c)\n","\n","print(transformed_c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtEQ2GD9XWpW","executionInfo":{"status":"ok","timestamp":1687693562344,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gagneet Kaur","userId":"01282326010698350277"}},"outputId":"e035bc9a-5806-4275-c3c4-388e8a856c94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 1.]\n"," [1. 0.]\n"," [2. 0.]\n"," [0. 1.]\n"," [3. 1.]\n"," [2. 0.]]\n"]}]},{"cell_type":"markdown","source":["#### iv. LabelBinarizer"],"metadata":{"id":"9_zh2LCoYpuI"}},{"cell_type":"markdown","source":["* Several regression and binary classification can be extended to multi-class setup in **one-vs-all** fashion.\n","*This involves training a single regressor or classifier per class.\n","*For this, we need to convert multi-class labels to binary labels, and **LabelBinarizer** performs this task\n","*If estimator supports multiclass data, LabelBinarizer is not needed.\n","\n"],"metadata":{"id":"wzUoCfo6YuJU"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelBinarizer"],"metadata":{"id":"70GUd9z3RHVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lb = LabelBinarizer()\n","lb.fit_transform(y)"],"metadata":{"id":"xq7_6nW2ROEB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####v. MultiLabelBinarizer"],"metadata":{"id":"RXqhvLYRRW5-"}},{"cell_type":"markdown","source":["* Encodes categorical features with value between 0 and K-1, where K is number of classes.\n","* In this example K=4, since there are only 4 genres of movies\n","\n","`movie_genres = [{'action', 'comedy'}, {'comedy'}, {'action', 'thriller'}, {'science-fiction', 'action', 'thriller'}]`"],"metadata":{"id":"TFVJ0sglR26K"}},{"cell_type":"code","source":["from sklearn.preprocessing import MultiLabelBinarizer"],"metadata":{"id":"o2GvPehKSuwh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlb = MultiLabelBinarizer()\n","mlb.fit_transform(movie_genres)"],"metadata":{"id":"_-yH4rNBS_h2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####vi. Add Dummy Feature"],"metadata":{"id":"fgvuE8gmTNd4"}},{"cell_type":"markdown","source":["`add_dummy_feature` augments dataset with a column vector, each value in the column vector is 1"],"metadata":{"id":"W2rCmWxCTb-6"}},{"cell_type":"code","source":["from sklearn.preprocessing import add_dummy_feature"],"metadata":{"id":"muet9FuiT3n_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["add_dummy_feature(X)"],"metadata":{"id":"t8bmn3oHTpyH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","##**PART 3 Feature Selection**"],"metadata":{"id":"FaN3iHMbVQ95"}},{"cell_type":"markdown","source":["* Sometimes in a real world dataset, all features do not contribute well enough towards fitting a model.\n","* The features that do not contribute significantly, can be removed. It leads to *decrease in size of the dataset* and ence the *computation cost* of a fitting model.\n","\n","`sklearn.feature_selection` provides many APIs to accomplish this task.\n","\n","The following are the classes present under the feature selection API :\n","\n","FILTER-BASED\n","  * VarianceThreshold\n","  * SelectKBest\n","  * SelectPercentile\n","  * GenericUnivariateSelect\n","\n","WRAPPER-BASED\n","  * RFE\n","  * RFECV\n","  * SelectFromModel\n","  * SequentialFeatureSelector"],"metadata":{"id":"8xOYetseVdcZ"}},{"cell_type":"markdown","source":["####i. Filter-Based Feature Selection"],"metadata":{"id":"NkB7bLdmXXUD"}},{"cell_type":"markdown","source":["1. Variance Threshold\n","\n","    * removes all features with variance below a certain threshold, as specified by the user, from input feature matrix.\n","\n","    * by default removes a feature which has same value, i.e. zero variance\n","\n","2. Univariate Feature Selection\n","\n","    It selects features based on univariate statistical tests. There are 3 APIs for univariate feature selection:\n","\n","    * **SelectKBest** - removes all but the k highest scoring features\n","    * **SelectPercentile** - removes all but a user-specified highest scoring percentage of features\n","    * **GenericUnivariateSelect** - performs univariate feature selection with a configurable strategy, which can be found via hyper-parameter search\n","\n","  sklearn provides one more class of univariate feature selection methods that work on common univariate statistical tests for each feature:\n","\n","    * `SelectFpr` selects features based on a false positive rate test\n","    * `SelectFdr` selects features based on an estimated false discovery rate\n","    * `SelectFwe` selects features based on family-wise error rate"],"metadata":{"id":"ULCFswSkk5S8"}},{"cell_type":"markdown","source":["#####**Univariate Scoring Function**\n"],"metadata":{"id":"W1JJvxWonfCP"}},{"cell_type":"markdown","source":["\n","  * Each API need a scoring function to score each feature.\n","  * Three classes of scoring functions are proposed:\n","      * Mutual Information (MI)\n","      * Chi-square\n","      * F-statistics\n","  * MI and F-statistics can be used in both `classification` and `regression` problems.\n","      * `mutual_info_regression`\n","      * `mutual_info_classif`\n","      * `f_regression`\n","      * `f_classif`\n","  * Chi-square can be used only in classification problems\n","      * `chi2`\n","\n","\n","**NOTE** : *Do not use regression feature scoring function with a classification problem. It will lead to useless results.*"],"metadata":{"id":"mTKpXhABGZrJ"}},{"cell_type":"markdown","source":["1. Mutual Information (MI)\n","\n","  * measures dependency between two variables\n","  * it returns a non-negative value.\n","      * `MI = 0` for `independent` variables\n","      * `Higher MI` indicates `higher dependency`\n","\n","2. Chi-square\n","\n","  * Measures dependence between two variables\n","  * Computes chi-square stats between `non-negative feature` (boolean or frequencies) and `class label`.\n","  * Higher chi-square values indicates that the features and labels are likely to be correlated. *(such features that are correlated with the labels are highly useful for classification problems)*"],"metadata":{"id":"suddsIUeo4ed"}},{"cell_type":"code","source":["from sklearn.feature_selection import SelectKBest, SelectPercentile, GenericUnivariateSelect, chi2"],"metadata":{"id":"u9smwrp5LhfR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#SelectKBest\n","\n","skb = SelectKBest(chi2, k=20) #selects 20 best features based on chi-square scoring function\n","X_new = skb.fit_transform(X,y)\n"],"metadata":{"id":"uHPeod4y62Tc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#SelectPercentile\n","\n","sp = SelectPercentile(chi2, percentile = 20) #selects top 20 percentile best features based on chi-square scoring function\n","X_new = sp.fit_transform(X,y)"],"metadata":{"id":"TASnbP0E7MBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GenericUnivariateSelect :\n","    # selects set of features based on a feature selection mode and a scoring function\n","    # the mode could be : mode = ['pencentile' --> default , 'k_best', 'fpr', 'fdr', 'fwe']\n","    # the param argument takes value corresponding to the mode\n","\n","transformer = GenericUnivariateSelect(chi2, mode = 'k_best', param = 20) #selects 20 best features based on chi-square scoring function\n","X_new = transformer.fit_transform(X, y)"],"metadata":{"id":"89jpRSa87keV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ii. Wrapper based filter selection"],"metadata":{"id":"c97ZcA9JGdKH"}},{"cell_type":"markdown","source":["Unlike filter based methods, wrapper based methods use `estimator class` rather than a `scoring function`"],"metadata":{"id":"Flzw_qQtGqZc"}},{"cell_type":"markdown","source":["1. Recursive Feature Elimination (RFE)\n","\n","  * Uses an estimator to recursively remove features.\n","    * Intitally fits an estimator on all features\n","  * Obtains feature importance from the estimator and removes the least important feature\n","  * Repeats the process by removing features one by one, until desired number of features are obtained.\n","\n","  **NOTE :**\n","\n","  Use RFECV if we don not want to specify the desired number of features in RFE.\n","\n","  It performs RFE in a cross-validation loop to find the optimal number of features."],"metadata":{"id":"j3bC7XO6HGn2"}},{"cell_type":"markdown","source":["2. SelectFromModel\n","\n","  * It selects the desired number of important features (as specified with `max_features` parameter) above **certain threshold of feature importance** as obtained **from the trained estimator**\n","  * The feature importance is obtained via `coef_` , `feature_importances_` or an `importance_getter` callable from the trained estimator.\n","  * The feature importance threshold can be specified either numerically or through string argument based on built-in heuristics such as `mean`, `median` and float multiples of these like `o.1*mean`"],"metadata":{"id":"c2JcuLyRIVtK"}},{"cell_type":"code","source":["from sklearn.feature_selection import SelectFromModel"],"metadata":{"id":"6FzdYViDLPct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf = LinearSVC(C=0.01, penalty='11', dual=False)\n","clf = clf.fit(X,y)\n","clf.coef__\n","\n","model = SelectFromModel(clf, prefit=True)\n","X_new = model.transform(X)"],"metadata":{"id":"yqbD8DZkKhsa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["  * Here we use a linear support vector classifier to get coefficients of features for `SelectFromModel` transformer.\n","  * It ends up selecting features with non-zero weights or coefficients."],"metadata":{"id":"A59zrVuyL0zx"}},{"cell_type":"markdown","source":["3. Sequential Feature Selection\n","\n","  * Performs feature selection by selecting or deselecting features one by one in a greedy manner.\n","  * Uses one of the two approaches:\n","    * Forward Selection:\n","\n","      * It starts with zero feature and then go on adding a feature one by one until the desired number of features are obtained.\n","\n","      * Starting with a zero feature, it finds one feature that obtains the best CV score for an estimator when trained on that feature\n","\n","      * Repeats the process by adding a new feature to the set of selected features.\n","\n","    * Backward Selection:\n","\n","      * It starts with all features and then go on deselecting or reducing features one by one until the desired number of features are obtained.\n","\n","      * Starting with all features and removes least important features one by one following the idea of forward selection.\n","\n","      Stop when reach the desired number of features.\n","\n","  * The `direction` parameter controls whether forward or backward SFS is used.\n","  * In general, forward and backward selection do not yield equivalent results.\n","  * Select the direction that is efficient for the required number of selected features:\n","    * When we want to select 7 out of 10 features,\n","      * Forward selection would need to perform 7 iterations.\n","      * Backward selection would only need to perform 3\n","    * Backward selection seems to be a reasonable choice here.\n","\n","  * SFS does not require the underlying model to expose a `coef_` or `feature_importances_` attributes unlike in `RFE` and `SelectFromModel`.\n","  * SFS may be slower than `RFE` and `SelectFromModel` as it needs to evaluate more models compared to the other two approaches.\n","\n","    For example in backward selection, the iteration going from ùñí features to\n","    m-1 features using ùê§-fold cross validation requires fitting ùñí x ùöî models, while:\n","\n","      * `RFE` would require only a single fit\n","      * `SelectFromModel` performs a single fit and requires no iterations\n"],"metadata":{"id":"0acLdymHQRzG"}},{"cell_type":"markdown","source":["####iii. Heterogeneous Feature Transformations"],"metadata":{"id":"7A2wsIq-DOGk"}},{"cell_type":"markdown","source":["* Generally training datat contains diverse features such as numeric and catgorical.\n","* Different feature types are processed with different transformers\n","* Need a way to combine different feature transformers seamlessly"],"metadata":{"id":"aYkR-4-XDf5r"}},{"cell_type":"markdown","source":["#####a. Composite Transformer"],"metadata":{"id":"ddAvRj5tFZ-a"}},{"cell_type":"markdown","source":["`sklearn.compose` has useful classes and methods to apply transformation on subset of features and combine them:\n","\n","  * Column Transformer\n","\n","    * It applies a set of transformers to columns of an array or `pandas.DataFrame`, concatenates the transformed outputs from different transformers into a single matrix.\n","    * It is useful for transforming heterogenous data by applying different transformers to separate subsets of features.\n","    * It combines different feature selection mechanisms and transformation into a single transformer object.\n","    * `ColumnTransformer()`\n","    * Each tuple has a format: `(estimatorName, estimator(..), columnIndices`"],"metadata":{"id":"iWoFCaE1Fpm6"}},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer"],"metadata":{"id":"W8ZUpHd0HaWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ColumnTransformer Example\n","  # In this example, lets apply MaxAbsScaler on the numeric column and OneHotEncoder on categorical column\n","\n","from sklearn.preprocessing import MaxAbsScaler, OneHotEncoder\n","\n","X = [[20.0, 'male'],\n","     [11.2, 'female'],\n","     [15.6, 'female'],\n","     [13.0, 'male'],\n","     [18.6, 'male'],\n","     [16.4, 'female']]\n","\n","listOfTrans = [('ageScaler', MaxAbsScaler(), [0]),('genderEncoder', OneHotEncoder(dtype = 'int'), [1])]\n","\n","column_trans = ColumnTransformer(listOfTrans, remainder='drop', verbose_feature_names_out=False)\n","\n","print(column_trans.fit_transform(X))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kh2RgYzvHfuo","executionInfo":{"status":"ok","timestamp":1688396705685,"user_tz":-330,"elapsed":5,"user":{"displayName":"GAGNEET KAUR","userId":"12023453577986092586"}},"outputId":"61444e2f-22c0-430a-b936-aff3fd8b5e1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.   0.   1.  ]\n"," [0.56 1.   0.  ]\n"," [0.78 1.   0.  ]\n"," [0.65 0.   1.  ]\n"," [0.93 0.   1.  ]\n"," [0.82 1.   0.  ]]\n"]}]},{"cell_type":"markdown","source":["#####b. Tranforming Target for Regression"],"metadata":{"id":"LzDNeMeMSf7A"}},{"cell_type":"markdown","source":["`TranformedTargetRegressor`\n","\n","  * Transforms the target variable `y` before fitting a regression model.\n","  * The predicted values are mapped back to the original space via an inverse transform.\n","  * `TransformedTargetRegressor` takes `regressor` and `transformer` to be applied to the target variable as arguments.\n"],"metadata":{"id":"dQCffnSIWsIz"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.compose import TransformedTargetRegressor\n","\n","tt = TransformedTargetRegressor(regressor = LinearRegression(), func = np.log, inverse_func = np.exp)\n","\n","X = np.arange(4).reshape(-1,1)\n","y = np.exp(2 * X).ravel()\n","tt.fit(X, y)"],"metadata":{"id":"zLppGnoMY7lB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**PART 4 Dimensionality Reduction by PCA**"],"metadata":{"id":"XOv7ArPnapeB"}},{"cell_type":"markdown","source":["Another way to reduce the number of features is through `unsupervised dimensionality reduction` techniques.\n","\n","`sklearn.decomposition` module has a number of APIs for this task.\n"],"metadata":{"id":"jzYh1mnFawah"}},{"cell_type":"markdown","source":["####PCA"],"metadata":{"id":"z1X5gBPJbtUf"}},{"cell_type":"markdown","source":["* PCA is a linear dimensionality reduction technique.\n","* It uses singular value decomposition(SVD) to project the feature matrix or data to a lower dimensional space.\n","* The first principle component (PC) is in the direction of `maximum variance` in the data\n","  * It captures bulk of the variance in the data\n","* The subsequent PCs are orthogonal to the first PC and gradually capture lesser and lesser variance in the data\n","* We can select first k PCs such that we are able to capture the desired variance\n","\n","`sklearn.decomposition.PCA` API is used for performing PCA based dimensionality reduction"],"metadata":{"id":"rxYCe-Zybykf"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA"],"metadata":{"id":"FsoMStwctj_F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **PART 5 Chaining Transformers**"],"metadata":{"id":"eDw5f5CTeOwn"}},{"cell_type":"markdown","source":["* The preprocessing transformations are applied one after another on the input feature matrix.\n","* It is important to apply exactly same transformation on training, evaluation and test set in the same order\n","* Failing to do so would lead to incorrect predictions from model due to distribution shift and hence incorrect performance evaluation"],"metadata":{"id":"sth0s4E2eTzG"}},{"cell_type":"markdown","source":["* The `sklearn.pipeline` module provides utilities to build a composite estimator, as a chain of transformers and estimators.\n","* There are 2 classes: *i. Pipeline* and *ii. FeatureUnion*"],"metadata":{"id":"LkHyYOYSgp3u"}},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline, make_pipeline"],"metadata":{"id":"B5vEpw_InNyr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####1. Pipeline\n","`sklearn.pipeline.Pipeline`\n","\n","\n"],"metadata":{"id":"7EkBwFRJhK9C"}},{"cell_type":"markdown","source":["  * Constructs a chain of multiple transformers to execute a fixed sequence of steps in data preprocessing and modelling\n","  * Sequentially apply a list of transformers and estimators\n","  * Intermediate steps of the pipeline must be \"transformers\" that is, they must implement fit and transform methods.\n","  * The final estimator only needs to implement fit\n","  * The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n"],"metadata":{"id":"CJbkP3kvrje_"}},{"cell_type":"markdown","source":["**Two ways to create a pipeline object**\n","    \n","  * `Pipeline()`\n","\n","      * It takes a list of `('estimatorName', estimator(..))` tuples.\n","      * The pipeline object exposes interface of the last step.\n","\n","    "],"metadata":{"id":"iDUBH2D9mDeM"}},{"cell_type":"code","source":["#Pipeline()\n","\n","estimators = [('simpleImputer', SimpleImputer()), ('standardScaler', StandardScaler())]\n","\n","pipe = Pipeline(steps = estimators)"],"metadata":{"id":"2JjJvxSjm0EL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* `make_pipeline()`\n","\n","    * It takes a number of estimator objects only."],"metadata":{"id":"S0b2Ijt0nj7j"}},{"cell_type":"code","source":["#make_pipeline()\n","\n","pipe = make_pipeline(SimpleImputer(), StandardScaler())"],"metadata":{"id":"zywtr9hPnW56"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Accessing individual steps in Pipeline**\n","\n"],"metadata":{"id":"i7Rh51F1pteA"}},{"cell_type":"code","source":["estimators = [ ('simpleImputer', SimpleImputer()), ('pca' , PCA()), ('regressor' , LinearRegression())]\n","\n","pipe = Pipeline(steps = estimators)"],"metadata":{"id":"tnoPu7fOq-CX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The second estimator can be accessed in the following 4 ways:\n","  * `pipe.named_steps.pca`\n","  * `pipe.steps[1]`\n","  * `pipe[1]`\n","  * `pipe['pca']`"],"metadata":{"id":"R0u2nFy-rBf_"}},{"cell_type":"markdown","source":["**Accessing parameters of each step in Pipeline**"],"metadata":{"id":"LrwW-hHTsRmH"}},{"cell_type":"markdown","source":["Parameters of the estimators in the pipeline can be accessed using the `<estimator>__<parameterName>` syntax\n","\n","(Note there are two underscores between `<estimator>` and `<parameterName>`)"],"metadata":{"id":"zN9xybCpsoPB"}},{"cell_type":"code","source":["estimators = [ ('simpleImputer', SimpleImputer()), ('pca' , PCA()), ('regressor' , LinearRegression())]\n","\n","pipe = Pipeline(steps = estimators)\n","\n","pipe.set_params(pca__n_components = 2)\n","\n","# here n_components of PCA() step is set after the pipeline is created"],"metadata":{"id":"LS6MHt7NtCck"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Performing grid search with pipeline**"],"metadata":{"id":"-agmakRfub6d"}},{"cell_type":"markdown","source":["By using naming convention of nested parameters, grid search can be implemented"],"metadata":{"id":"VVZ3A3kougxt"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","param_grid = dict(imputer = ['passthrough', SimpleImputer(), KNNImputer()], clf = [SVC(), LogisticRegression()], clf__C = [0.1,10,100])\n","\n","grid_search = GridSearchCV(pipe, param_grid = param_grid)"],"metadata":{"id":"LcAWBeC6un59"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* By `passthrough` we mean that we do not want to perform any imputation\n","\n","* `C` is an inverse of regularization, lower its value stronger the regularization is.\n","\n","* In the example above `clf__C` provides a set of values for grid search"],"metadata":{"id":"Tog9ZUsPvvW7"}},{"cell_type":"markdown","source":["**Caching transformers**"],"metadata":{"id":"7z9IobOow3EM"}},{"cell_type":"markdown","source":["* Transforming data is a computationally expensive step\n","* For grid search, transformers need not be applied for every parameter configuration. They can be applied only once, and the transformed data can be reused.\n","* This can be achieved by setting `memory` parameter of a pipeline object\n","* `memory` can take either location of a directory in string format or `joblib.Memory` object.\n"],"metadata":{"id":"G3rfBanrxFlD"}},{"cell_type":"code","source":["estimators = [ ('simpleImputer', SimpleImputer()), ('pca' , PCA()), ('regressor' , LinearRegression())]\n","\n","pipe = Pipeline(steps = estimators, memory = '/path/to/cache/dir')"],"metadata":{"id":"q0OTAif92JXP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Advantages of Pipeline**"],"metadata":{"id":"i2v7tI7S2WFa"}},{"cell_type":"markdown","source":["* Combines multiple steps of end to end ML into single object such as `missing value imputation`, `feature scaling` and `encoding`, `model training` and `cross validation`.\n","\n","* Enables joint grid search over parameters of all the estimators in the pipeline.\n","\n","* Makes configuring and tuning end to end ML quick and easy.\n","\n","* Offers convinience, as a developer has to call `fit()` and `predict()` methods only on a `Pipeline` object (assuming last step in the pipeline is an estimator)\n","\n","* Reduces code duplication : With a `Pipeline` object, one doesn't have to repeat code for preprocessing and transforming the test data."],"metadata":{"id":"t-hDuM8E2ht_"}},{"cell_type":"markdown","source":["####2. FeatureUnion\n","`sklearn.pipeline.FeatureUnion`"],"metadata":{"id":"3K4PrcK8hwfj"}},{"cell_type":"markdown","source":["* Combines output from several transformer objects by creating a new transformer from them.\n","\n","* Concatenates `results` of multiple transformer objects.\n","\n","* Applies a list of transformer objects in parallel, and their outputs are concatenated side-by-side into a larger matrix\n","\n","* `FeatureUnion` and `Pipeline` can be used to create complex transformers"],"metadata":{"id":"XMEFI41dsHJI"}},{"cell_type":"code","source":["from sklearn.pipeline import FeatureUnion"],"metadata":{"id":"VEHybfHr9WgR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Combining Transformers and Pipelines**"],"metadata":{"id":"D55mhc945LeF"}},{"cell_type":"markdown","source":["* `FeatureUnion` accepts a list of tuples\n","* Each tuple is of format: `('estimatorName', estimator(...))`"],"metadata":{"id":"0DoWa_fU76lc"}},{"cell_type":"code","source":["num_pipeline = Pipeline(\n","    [('selector', ColumnTransformer([('select_first_4', 'passthrough', slice(0,4))])),\n","     ('imputer', SimpleImputer(strategy = 'median')),\n","     ('std_scaler', StandardScaler())])\n","\n","cat_pipeline = ColumnTransformer([('label_binarizer', LabelBinarizer(), [4])])\n","\n","full_pipeline = FeatureUnion(transformer_list = [(\"num_pipeline\", num_pipeline), (\"cat_pipeline\", cat_pipeline)])"],"metadata":{"id":"2rGRFfuL8MmQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Visualizing Composite Transformers**"],"metadata":{"id":"Ryrm_Iqt9j26"}},{"cell_type":"code","source":["from sklearn import set_config\n","set_config(display = 'diagram') #displays HTML representation in a jupyter context\n","full_pipeline"],"metadata":{"id":"iQHHotl29kPa"},"execution_count":null,"outputs":[]}]}